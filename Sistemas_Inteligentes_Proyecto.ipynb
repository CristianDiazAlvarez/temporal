{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4-IodMt3yc1"
   },
   "source": [
    "### Detección de Diabetes usando ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THPKcT3Q3eCt"
   },
   "source": [
    "[Implementación RBF-NN](https://towardsdatascience.com/most-effective-way-to-implement-radial-basis-function-neural-network-for-classification-problem-33c467803319)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "YFUM9Mg5yM8T"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EhxtfeWXmpCV"
   },
   "source": [
    "### Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "Suw2xJOJ0Q3z",
    "outputId": "8ccd4f1e-fd8c-4e13-b237-cac72fe12707"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'temporal' already exists and is not an empty directory.\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Gender Polyuria Polydipsia sudden weight loss weakness Polyphagia  \\\n",
       "0   40   Male       No        Yes                 No      Yes         No   \n",
       "1   58   Male       No         No                 No      Yes         No   \n",
       "2   41   Male      Yes         No                 No      Yes        Yes   \n",
       "3   45   Male       No         No                Yes      Yes        Yes   \n",
       "4   60   Male      Yes        Yes                Yes      Yes        Yes   \n",
       "\n",
       "  Genital thrush visual blurring Itching Irritability delayed healing  \\\n",
       "0             No              No     Yes           No             Yes   \n",
       "1             No             Yes      No           No              No   \n",
       "2             No              No     Yes           No             Yes   \n",
       "3            Yes              No     Yes           No             Yes   \n",
       "4             No             Yes     Yes          Yes             Yes   \n",
       "\n",
       "  partial paresis muscle stiffness Alopecia Obesity     class  \n",
       "0              No              Yes      Yes     Yes  Positive  \n",
       "1             Yes               No      Yes      No  Positive  \n",
       "2              No              Yes      Yes      No  Positive  \n",
       "3              No               No       No      No  Positive  \n",
       "4             Yes              Yes      Yes     Yes  Positive  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!git clone https://github.com/CristianDiazAlvarez/temporal.git\n",
    "df = pd.read_csv(\"temporal/diabetes_data_upload.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "-qYwnYRR04_P",
    "outputId": "37b870c3-7e46-4770-f9fa-a6d5267aed6d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Polyuria</th>\n",
       "      <th>Polydipsia</th>\n",
       "      <th>sudden weight loss</th>\n",
       "      <th>weakness</th>\n",
       "      <th>Polyphagia</th>\n",
       "      <th>Genital thrush</th>\n",
       "      <th>visual blurring</th>\n",
       "      <th>Itching</th>\n",
       "      <th>Irritability</th>\n",
       "      <th>delayed healing</th>\n",
       "      <th>partial paresis</th>\n",
       "      <th>muscle stiffness</th>\n",
       "      <th>Alopecia</th>\n",
       "      <th>Obesity</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337838</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.391892</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.594595</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>515</td>\n",
       "      <td>0.310811</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>516</td>\n",
       "      <td>0.432432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>517</td>\n",
       "      <td>0.567568</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>518</td>\n",
       "      <td>0.216216</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>519</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>520 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Age  Gender  Polyuria  Polydipsia  sudden weight loss  weakness  \\\n",
       "0    0.324324       1         0           1                   0         1   \n",
       "1    0.567568       1         0           0                   0         1   \n",
       "2    0.337838       1         1           0                   0         1   \n",
       "3    0.391892       1         0           0                   1         1   \n",
       "4    0.594595       1         1           1                   1         1   \n",
       "..        ...     ...       ...         ...                 ...       ...   \n",
       "515  0.310811       0         1           1                   1         0   \n",
       "516  0.432432       0         1           1                   1         1   \n",
       "517  0.567568       0         1           1                   1         1   \n",
       "518  0.216216       0         0           0                   0         1   \n",
       "519  0.351351       1         0           0                   0         0   \n",
       "\n",
       "     Polyphagia  Genital thrush  visual blurring  Itching  Irritability  \\\n",
       "0             0               0                0        1             0   \n",
       "1             0               0                1        0             0   \n",
       "2             1               0                0        1             0   \n",
       "3             1               1                0        1             0   \n",
       "4             1               0                1        1             1   \n",
       "..          ...             ...              ...      ...           ...   \n",
       "515           1               0                0        1             0   \n",
       "516           1               0                0        1             1   \n",
       "517           1               0                1        0             0   \n",
       "518           0               0                1        1             0   \n",
       "519           0               0                0        0             0   \n",
       "\n",
       "     delayed healing  partial paresis  muscle stiffness  Alopecia  Obesity  \\\n",
       "0                  1                0                 1         1        1   \n",
       "1                  0                1                 0         1        0   \n",
       "2                  1                0                 1         1        0   \n",
       "3                  1                0                 0         0        0   \n",
       "4                  1                1                 1         1        1   \n",
       "..               ...              ...               ...       ...      ...   \n",
       "515                1                1                 0         0        0   \n",
       "516                1                1                 0         0        0   \n",
       "517                0                1                 1         0        1   \n",
       "518                1                0                 0         1        0   \n",
       "519                0                0                 0         0        0   \n",
       "\n",
       "     class  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "..     ...  \n",
       "515      1  \n",
       "516      1  \n",
       "517      1  \n",
       "518      0  \n",
       "519      0  \n",
       "\n",
       "[520 rows x 17 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[:,1:] = df.iloc[:,1:].apply(LabelEncoder().fit_transform)\n",
    "df[\"Age\"] -= df[\"Age\"].min()\n",
    "df[\"Age\"] /= df[\"Age\"].max() - df[\"Age\"].min()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5sm9v-uR8WpO"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "WyJrNtdt5Wvr",
    "outputId": "d06b8278-97ef-4a60-a8f3-10ee19674a55"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff435e36410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Age\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "3LOsrqTI6hin"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "naPkYSQ5myTX"
   },
   "source": [
    "### ANN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iteh7VWC3QSw"
   },
   "source": [
    "#### Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "HJghydWp3OYf"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "mWOE9W-rauvY",
    "outputId": "7740f9ce-23ca-4c1c-a62d-992bb4fdc071"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cristiandiazalvarez/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   32.7s\n",
      "[Parallel(n_jobs=-1)]: Done 243 out of 243 | elapsed:   42.5s finished\n",
      "/Users/cristiandiazalvarez/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=MLPClassifier(activation='relu', alpha=0.0001,\n",
       "                                     batch_size='auto', beta_1=0.9,\n",
       "                                     beta_2=0.999, early_stopping=False,\n",
       "                                     epsilon=1e-08, hidden_layer_sizes=(100,),\n",
       "                                     learning_rate='constant',\n",
       "                                     learning_rate_init=0.001, max_iter=200,\n",
       "                                     momentum=0.9, n_iter_no_change=10,\n",
       "                                     nesterovs_momentum=True, power_t=0.5,\n",
       "                                     rando...\n",
       "                                     validation_fraction=0.1, verbose=False,\n",
       "                                     warm_start=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid={'alpha': array([1.e-03, 1.e-04, 1.e-05]),\n",
       "                         'hidden_layer_sizes': [16, (32, 16), (32, 12, 4)],\n",
       "                         'max_iter': [1000, 10000, 100000],\n",
       "                         'random_state': [0, 1, 10], 'solver': ['adam'],\n",
       "                         'validation_fraction': [0.3]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'solver': ['adam'], \n",
    " 'max_iter': [1000,10000,100000], \n",
    " 'alpha': 10.0 ** -np.arange(3, 6), \n",
    " 'hidden_layer_sizes':[(16),(32,16),(32,12,4)], \n",
    " 'random_state':[0,1,10],\n",
    "  'validation_fraction':[0.3]}\n",
    "clf = GridSearchCV(MLPClassifier(), parameters, n_jobs=-1, verbose=1, return_train_score = True)\n",
    " \n",
    "clf.fit(df.iloc[:,:-1], df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vjaiMNb906iF"
   },
   "source": [
    "#### Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "mjHyL-BqbQsa",
    "outputId": "b70024fc-e578-433a-ee09-0ff34a2e7009"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_validation_fraction</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.281316</td>\n",
       "      <td>0.133462</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.023951</td>\n",
       "      <td>52</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.989419</td>\n",
       "      <td>0.004919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.121589</td>\n",
       "      <td>0.075285</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.948077</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>70</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.992304</td>\n",
       "      <td>0.002733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.152893</td>\n",
       "      <td>0.097503</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.936782</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.953846</td>\n",
       "      <td>0.020322</td>\n",
       "      <td>22</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.006251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.232092</td>\n",
       "      <td>0.134263</td>\n",
       "      <td>0.001741</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.023951</td>\n",
       "      <td>52</td>\n",
       "      <td>0.982659</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.989419</td>\n",
       "      <td>0.004919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.084703</td>\n",
       "      <td>0.101318</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.001</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.948077</td>\n",
       "      <td>0.026001</td>\n",
       "      <td>70</td>\n",
       "      <td>0.988439</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.992304</td>\n",
       "      <td>0.002733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.308875</td>\n",
       "      <td>0.215877</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>37</td>\n",
       "      <td>0.985549</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.991352</td>\n",
       "      <td>0.006233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>3.056963</td>\n",
       "      <td>1.121885</td>\n",
       "      <td>0.001847</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.821154</td>\n",
       "      <td>0.144053</td>\n",
       "      <td>79</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.614943</td>\n",
       "      <td>0.864904</td>\n",
       "      <td>0.176942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.886153</td>\n",
       "      <td>0.060674</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.025731</td>\n",
       "      <td>52</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.257637</td>\n",
       "      <td>0.178266</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.976744</td>\n",
       "      <td>0.951923</td>\n",
       "      <td>0.018821</td>\n",
       "      <td>37</td>\n",
       "      <td>0.985549</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.988506</td>\n",
       "      <td>0.991352</td>\n",
       "      <td>0.006233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>2.386998</td>\n",
       "      <td>0.821799</td>\n",
       "      <td>0.001376</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.616279</td>\n",
       "      <td>0.821154</td>\n",
       "      <td>0.144053</td>\n",
       "      <td>79</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.614943</td>\n",
       "      <td>0.864904</td>\n",
       "      <td>0.176942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        1.281316      0.133462         0.003209        0.002015       0.001   \n",
       "1        1.121589      0.075285         0.002126        0.000443       0.001   \n",
       "2        1.152893      0.097503         0.001772        0.000029       0.001   \n",
       "3        1.232092      0.134263         0.001741        0.000081       0.001   \n",
       "4        1.084703      0.101318         0.001758        0.000026       0.001   \n",
       "..            ...           ...              ...             ...         ...   \n",
       "76       1.308875      0.215877         0.002121        0.000107       1e-05   \n",
       "77       3.056963      1.121885         0.001847        0.000275       1e-05   \n",
       "78       0.886153      0.060674         0.002168        0.000079       1e-05   \n",
       "79       1.257637      0.178266         0.002095        0.000164       1e-05   \n",
       "80       2.386998      0.821799         0.001376        0.000270       1e-05   \n",
       "\n",
       "   param_hidden_layer_sizes param_max_iter param_random_state param_solver  \\\n",
       "0                        16           1000                  0         adam   \n",
       "1                        16           1000                  1         adam   \n",
       "2                        16           1000                 10         adam   \n",
       "3                        16          10000                  0         adam   \n",
       "4                        16          10000                  1         adam   \n",
       "..                      ...            ...                ...          ...   \n",
       "76              (32, 12, 4)          10000                  1         adam   \n",
       "77              (32, 12, 4)          10000                 10         adam   \n",
       "78              (32, 12, 4)         100000                  0         adam   \n",
       "79              (32, 12, 4)         100000                  1         adam   \n",
       "80              (32, 12, 4)         100000                 10         adam   \n",
       "\n",
       "   param_validation_fraction  ... split1_test_score  split2_test_score  \\\n",
       "0                        0.3  ...          0.925287           0.982558   \n",
       "1                        0.3  ...          0.919540           0.982558   \n",
       "2                        0.3  ...          0.936782           0.982558   \n",
       "3                        0.3  ...          0.925287           0.982558   \n",
       "4                        0.3  ...          0.919540           0.982558   \n",
       "..                       ...  ...               ...                ...   \n",
       "76                       0.3  ...          0.931034           0.976744   \n",
       "77                       0.3  ...          0.925287           0.616279   \n",
       "78                       0.3  ...          0.919540           0.982558   \n",
       "79                       0.3  ...          0.931034           0.976744   \n",
       "80                       0.3  ...          0.925287           0.616279   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "0          0.950000        0.023951               52            0.982659   \n",
       "1          0.948077        0.026001               70            0.988439   \n",
       "2          0.953846        0.020322               22            0.979769   \n",
       "3          0.950000        0.023951               52            0.982659   \n",
       "4          0.948077        0.026001               70            0.988439   \n",
       "..              ...             ...              ...                 ...   \n",
       "76         0.951923        0.018821               37            0.985549   \n",
       "77         0.821154        0.144053               79            0.979769   \n",
       "78         0.950000        0.025731               52            0.991329   \n",
       "79         0.951923        0.018821               37            0.985549   \n",
       "80         0.821154        0.144053               79            0.979769   \n",
       "\n",
       "    split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "0              0.99422            0.991379          0.989419         0.004919  \n",
       "1              0.99422            0.994253          0.992304         0.002733  \n",
       "2              0.99422            0.991379          0.988456         0.006251  \n",
       "3              0.99422            0.991379          0.989419         0.004919  \n",
       "4              0.99422            0.994253          0.992304         0.002733  \n",
       "..                 ...                 ...               ...              ...  \n",
       "76             1.00000            0.988506          0.991352         0.006233  \n",
       "77             1.00000            0.614943          0.864904         0.176942  \n",
       "78             1.00000            0.994253          0.995194         0.003602  \n",
       "79             1.00000            0.988506          0.991352         0.006233  \n",
       "80             1.00000            0.614943          0.864904         0.176942  \n",
       "\n",
       "[81 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(clf.cv_results_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_hidden_layer_sizes</th>\n",
       "      <th>param_max_iter</th>\n",
       "      <th>param_random_state</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>param_validation_fraction</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.893329</td>\n",
       "      <td>0.049558</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.838954</td>\n",
       "      <td>0.017923</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.835160</td>\n",
       "      <td>0.054240</td>\n",
       "      <td>0.002381</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.965385</td>\n",
       "      <td>0.024359</td>\n",
       "      <td>1</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.860680</td>\n",
       "      <td>0.042197</td>\n",
       "      <td>0.002292</td>\n",
       "      <td>0.000472</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.875288</td>\n",
       "      <td>0.045487</td>\n",
       "      <td>0.003943</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.878601</td>\n",
       "      <td>0.069140</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.886773</td>\n",
       "      <td>0.045451</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.858532</td>\n",
       "      <td>0.065871</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.000812</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.780677</td>\n",
       "      <td>0.055495</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919540</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.959615</td>\n",
       "      <td>0.028509</td>\n",
       "      <td>4</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.851914</td>\n",
       "      <td>0.109215</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.880729</td>\n",
       "      <td>0.096028</td>\n",
       "      <td>0.003459</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.820810</td>\n",
       "      <td>0.065730</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>1e-05</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.925287</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.957692</td>\n",
       "      <td>0.024008</td>\n",
       "      <td>10</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.909923</td>\n",
       "      <td>0.122920</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.946033</td>\n",
       "      <td>0.143040</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.000316</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 16)</td>\n",
       "      <td>100000</td>\n",
       "      <td>1</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.244675</td>\n",
       "      <td>0.139695</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.000314</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>100000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>13</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.006251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.899679</td>\n",
       "      <td>0.046814</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.228680</td>\n",
       "      <td>0.117024</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>10000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>13</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.006251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.861970</td>\n",
       "      <td>0.054737</td>\n",
       "      <td>0.002336</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>10000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.856395</td>\n",
       "      <td>0.041381</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>(32, 12, 4)</td>\n",
       "      <td>100000</td>\n",
       "      <td>0</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.021050</td>\n",
       "      <td>13</td>\n",
       "      <td>0.991329</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.994253</td>\n",
       "      <td>0.995194</td>\n",
       "      <td>0.003602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.222141</td>\n",
       "      <td>0.117824</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>16</td>\n",
       "      <td>1000</td>\n",
       "      <td>10</td>\n",
       "      <td>adam</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942529</td>\n",
       "      <td>0.982558</td>\n",
       "      <td>0.955769</td>\n",
       "      <td>0.018833</td>\n",
       "      <td>13</td>\n",
       "      <td>0.979769</td>\n",
       "      <td>0.99422</td>\n",
       "      <td>0.991379</td>\n",
       "      <td>0.988456</td>\n",
       "      <td>0.006251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "65       0.893329      0.049558         0.002025        0.000011       1e-05   \n",
       "71       0.838954      0.017923         0.002512        0.000620       1e-05   \n",
       "68       0.835160      0.054240         0.002381        0.000258       1e-05   \n",
       "38       0.860680      0.042197         0.002292        0.000472      0.0001   \n",
       "17       0.875288      0.045487         0.003943        0.002286       0.001   \n",
       "44       0.878601      0.069140         0.002063        0.000061      0.0001   \n",
       "14       0.886773      0.045451         0.002274        0.000559       0.001   \n",
       "41       0.858532      0.065871         0.002671        0.000812      0.0001   \n",
       "11       0.780677      0.055495         0.001862        0.000028       0.001   \n",
       "66       0.851914      0.109215         0.002045        0.000041       1e-05   \n",
       "63       0.880729      0.096028         0.003459        0.001496       1e-05   \n",
       "69       0.820810      0.065730         0.002368        0.000235       1e-05   \n",
       "37       0.909923      0.122920         0.002385        0.000540      0.0001   \n",
       "43       0.946033      0.143040         0.002079        0.000316      0.0001   \n",
       "35       1.244675      0.139695         0.002387        0.000314      0.0001   \n",
       "45       0.899679      0.046814         0.002202        0.000083      0.0001   \n",
       "32       1.228680      0.117024         0.002164        0.000415      0.0001   \n",
       "48       0.861970      0.054737         0.002336        0.000143      0.0001   \n",
       "51       0.856395      0.041381         0.002111        0.000045      0.0001   \n",
       "29       1.222141      0.117824         0.002094        0.000146      0.0001   \n",
       "\n",
       "   param_hidden_layer_sizes param_max_iter param_random_state param_solver  \\\n",
       "65                 (32, 16)           1000                 10         adam   \n",
       "71                 (32, 16)         100000                 10         adam   \n",
       "68                 (32, 16)          10000                 10         adam   \n",
       "38                 (32, 16)           1000                 10         adam   \n",
       "17                 (32, 16)         100000                 10         adam   \n",
       "44                 (32, 16)         100000                 10         adam   \n",
       "14                 (32, 16)          10000                 10         adam   \n",
       "41                 (32, 16)          10000                 10         adam   \n",
       "11                 (32, 16)           1000                 10         adam   \n",
       "66                 (32, 16)          10000                  0         adam   \n",
       "63                 (32, 16)           1000                  0         adam   \n",
       "69                 (32, 16)         100000                  0         adam   \n",
       "37                 (32, 16)           1000                  1         adam   \n",
       "43                 (32, 16)         100000                  1         adam   \n",
       "35                       16         100000                 10         adam   \n",
       "45              (32, 12, 4)           1000                  0         adam   \n",
       "32                       16          10000                 10         adam   \n",
       "48              (32, 12, 4)          10000                  0         adam   \n",
       "51              (32, 12, 4)         100000                  0         adam   \n",
       "29                       16           1000                 10         adam   \n",
       "\n",
       "   param_validation_fraction  ... split1_test_score  split2_test_score  \\\n",
       "65                       0.3  ...          0.931034           0.982558   \n",
       "71                       0.3  ...          0.931034           0.982558   \n",
       "68                       0.3  ...          0.931034           0.982558   \n",
       "38                       0.3  ...          0.919540           0.982558   \n",
       "17                       0.3  ...          0.919540           0.982558   \n",
       "44                       0.3  ...          0.919540           0.982558   \n",
       "14                       0.3  ...          0.919540           0.982558   \n",
       "41                       0.3  ...          0.919540           0.982558   \n",
       "11                       0.3  ...          0.919540           0.982558   \n",
       "66                       0.3  ...          0.925287           0.982558   \n",
       "63                       0.3  ...          0.925287           0.982558   \n",
       "69                       0.3  ...          0.925287           0.982558   \n",
       "37                       0.3  ...          0.931034           0.982558   \n",
       "43                       0.3  ...          0.931034           0.982558   \n",
       "35                       0.3  ...          0.942529           0.982558   \n",
       "45                       0.3  ...          0.931034           0.982558   \n",
       "32                       0.3  ...          0.942529           0.982558   \n",
       "48                       0.3  ...          0.931034           0.982558   \n",
       "51                       0.3  ...          0.931034           0.982558   \n",
       "29                       0.3  ...          0.942529           0.982558   \n",
       "\n",
       "    mean_test_score  std_test_score  rank_test_score  split0_train_score  \\\n",
       "65         0.965385        0.024359                1            0.991329   \n",
       "71         0.965385        0.024359                1            0.991329   \n",
       "68         0.965385        0.024359                1            0.991329   \n",
       "38         0.959615        0.028509                4            0.991329   \n",
       "17         0.959615        0.028509                4            0.991329   \n",
       "44         0.959615        0.028509                4            0.991329   \n",
       "14         0.959615        0.028509                4            0.991329   \n",
       "41         0.959615        0.028509                4            0.991329   \n",
       "11         0.959615        0.028509                4            0.991329   \n",
       "66         0.957692        0.024008               10            0.991329   \n",
       "63         0.957692        0.024008               10            0.991329   \n",
       "69         0.957692        0.024008               10            0.991329   \n",
       "37         0.955769        0.021050               13            0.991329   \n",
       "43         0.955769        0.021050               13            0.991329   \n",
       "35         0.955769        0.018833               13            0.979769   \n",
       "45         0.955769        0.021050               13            0.991329   \n",
       "32         0.955769        0.018833               13            0.979769   \n",
       "48         0.955769        0.021050               13            0.991329   \n",
       "51         0.955769        0.021050               13            0.991329   \n",
       "29         0.955769        0.018833               13            0.979769   \n",
       "\n",
       "    split1_train_score  split2_train_score  mean_train_score  std_train_score  \n",
       "65             1.00000            0.994253          0.995194         0.003602  \n",
       "71             1.00000            0.994253          0.995194         0.003602  \n",
       "68             1.00000            0.994253          0.995194         0.003602  \n",
       "38             1.00000            0.994253          0.995194         0.003602  \n",
       "17             1.00000            0.994253          0.995194         0.003602  \n",
       "44             1.00000            0.994253          0.995194         0.003602  \n",
       "14             1.00000            0.994253          0.995194         0.003602  \n",
       "41             1.00000            0.994253          0.995194         0.003602  \n",
       "11             1.00000            0.994253          0.995194         0.003602  \n",
       "66             1.00000            0.994253          0.995194         0.003602  \n",
       "63             1.00000            0.994253          0.995194         0.003602  \n",
       "69             1.00000            0.994253          0.995194         0.003602  \n",
       "37             1.00000            0.994253          0.995194         0.003602  \n",
       "43             1.00000            0.994253          0.995194         0.003602  \n",
       "35             0.99422            0.991379          0.988456         0.006251  \n",
       "45             1.00000            0.994253          0.995194         0.003602  \n",
       "32             0.99422            0.991379          0.988456         0.006251  \n",
       "48             1.00000            0.994253          0.995194         0.003602  \n",
       "51             1.00000            0.994253          0.995194         0.003602  \n",
       "29             0.99422            0.991379          0.988456         0.006251  \n",
       "\n",
       "[20 rows x 22 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results = pd.DataFrame(clf.cv_results_)\n",
    "pd_results = pd_results.sort_values(by='rank_test_score',ascending=True)\n",
    "pd_results.head(20)\n",
    "#best_idx = pd_results['rank_test_score'].sort_values(reverse=True)\n",
    "\n",
    "#pd.set_option('display.max_columns', None)\n",
    "#pd.DataFrame(pd_results[best_idx:best_idx+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "0q2BBoy808v2",
    "outputId": "66a9280a-3711-40c9-f86f-245e46c58d5b"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "vXOhEEZX6Tz5",
    "outputId": "e1654402-38b5-42a0-cac1-09a26ab9595e"
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-3,hidden_layer_sizes=(1,), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "iJvYx3le9tgv",
    "outputId": "9eafec75-623d-466b-a0df-bd9b949dd08f"
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-4,hidden_layer_sizes=(1,), random_state=1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "clFxXqS7_h4A",
    "outputId": "7aec2f76-bfbb-46b9-834f-84481d10ffe0"
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-4,hidden_layer_sizes=(1,1,1), random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HzUnfiDz6yoV"
   },
   "source": [
    "## Entrenamiento de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_xzpCCMY6xaV"
   },
   "outputs": [],
   "source": [
    "# importar librerias de keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0pJZDcte7gh7"
   },
   "outputs": [],
   "source": [
    "# definir estructura de la red neuronal\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=16, activation='relu'))\n",
    "model.add(Dense(34, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkJD9hnF7s3d"
   },
   "outputs": [],
   "source": [
    "# compilar red neuronal\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "_sgRZsPgTsBf",
    "outputId": "e3db0e8d-09f9-4f12-faf8-cea5008346ed"
   },
   "outputs": [],
   "source": [
    "len(X_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "zupNPmKb7yv-",
    "outputId": "d7738187-d3f5-4a25-c762-f4ae8e29cb4c"
   },
   "outputs": [],
   "source": [
    "# entrenar la red neuronal ajustando sus pesos basado en los datos de entrenamiento\n",
    "model.fit(X_train.to_numpy(), y_train.to_numpy(), epochs=100, batch_size=10, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "ZooQoBtA8Jkv",
    "outputId": "6029857b-c8da-4718-e8e4-237a34c00a20"
   },
   "outputs": [],
   "source": [
    "# evaluar el desempeño del modelo\n",
    "loss, accuracy = model.evaluate(X_test.to_numpy(), y_test.to_numpy())\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "print('Loss: %.2f' % (loss*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "pFepyvgW_XUw",
    "outputId": "513e25b3-a6b9-4319-c6fa-a10b486c4640"
   },
   "outputs": [],
   "source": [
    "# make class predictions with the model\n",
    "predictions = model.predict(X_test.to_numpy())\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (X_test.to_numpy()[i].tolist(), predictions[i], y_test.to_numpy()[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "KQlYHzMGWawg",
    "outputId": "9984256d-45d7-4d54-bf00-144ef4a70c33"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test.to_numpy(), predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F8hjKmyNZgJB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sistemas Inteligentes - Proyecto.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
